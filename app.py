import streamlit as st
import pandas as pd
import google.generativeai as genai
import os
import glob
import re
import numpy as np
import os
from pathlib import Path

# ==========================================
# 1. í™˜ê²½ ì„¤ì • ë° API í‚¤
# ==========================================
st.set_page_config(page_title="K-í•˜ì´í…Œí¬ êµìœ¡ ì¶”ì²œ(ìµœì¢…)", layout="wide", page_icon="ğŸ­")

# âš ï¸ ê²½ë¡œ ìˆ˜ì • (ì‚¬ìš©ì ì§€ì • ê²½ë¡œ)
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

# âš ï¸ API í‚¤ ì…ë ¥ í•„ìˆ˜
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY", ""))

if not GOOGLE_API_KEY:
    st.error("âš ï¸ ì½”ë“œ ë‚´ 'GOOGLE_API_KEY' ë³€ìˆ˜ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()
else:
    genai.configure(api_key=GOOGLE_API_KEY)


# ==========================================
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Curriculum & RAG)
# ==========================================
def normalize_course_name(name):
    if not isinstance(name, str): return ""
    name = re.sub(r'\(.*?\)', '', name)  # ê´„í˜¸ ì œê±°
    name = re.sub(r'\[.*?\]', '', name)  # ëŒ€ê´„í˜¸ ì œê±°
    for suffix in ["ì–‘ì„±ê³¼ì •", "í›ˆë ¨ê³¼ì •", "êµìœ¡ê³¼ì •", "ê³¼ì •"]:
        name = name.replace(suffix, "")
    name = re.sub(r'\d+(ê¸°|ì°¨|íšŒ|ë‹¨ê³„|Step)', '', name, flags=re.IGNORECASE)
    return name.strip()


@st.cache_data
def load_all_data(base_path):
    if not os.path.exists(base_path): return [], [], {}, ""

    # ---------------------------------------------------------
    # 1. [ê¸°ì¤€] ê°•ì¢Œëª….csv (Master List)
    # ---------------------------------------------------------
    master_file = os.path.join(DATA_DIR, "02_ê°•ì˜_meta_Data.csv")
    valid_courses = []
    if os.path.exists(master_file):
        try:
        # ì¸ì½”ë”© ì•ˆì „ ì²˜ë¦¬
            try:
                df_master = pd.read_csv(master_file, encoding="cp949")
            except UnicodeDecodeError:
                df_master = pd.read_csv(master_file, encoding="utf-8-sig")

            # ì»¬ëŸ¼ëª… í™•ì¸
            st.write("df_master columns:", df_master.columns.tolist())

            # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°(ì•ˆì „ì¥ì¹˜)
            df_master.columns = df_master.columns.astype(str).str.strip()

            # í•„ìš”í•œ ì»¬ëŸ¼ ì¡´ì¬ ê²€ì‚¬
            col = "í›ˆë ¨ê³¼ì •ëª…(ì •ë‹µë¼ë²¨)"
            if col not in df_master.columns:
                st.error(f"âš ï¸ '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ì»¬ëŸ¼: {df_master.columns.tolist()}")
            else:
                valid_courses = df_master[col].dropna().astype(str).unique().tolist()
                st.success(f"âœ… valid_courses ë¡œë“œ ì„±ê³µ: {len(valid_courses)}ê°œ")

        except Exception as e:
            st.exception(e)
    else:
        st.error("âš ï¸ master_file ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ---------------------------------------------------------
    # 2. [êµ¬ì¡°] ì»¤ë¦¬í˜ëŸ¼.csv (Curriculum Tracks)
    # ---------------------------------------------------------
    curr_file = os.path.join(DATA_DIR, "03_ì „ì²´_ì»¤ë¦¬í˜ëŸ¼.csv")
    curriculum_text = ""
    if os.path.exists(curr_file):
        try:
            try:
                df_curr = pd.read_csv(curr_file, encoding='cp949')
            except:
                df_curr = pd.read_csv(curr_file, encoding='utf-8')

            # í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            # í˜•ì‹: [íŠ¸ë™ëª…] ê³¼ì •1 -> ê³¼ì •2 -> ê³¼ì •3 ...
            grouped = df_curr.groupby(['íŠ¸ë™ID', 'íŠ¸ë™ëª…', 'íŠ¸ë™ì„¤ëª…'])
            for (tid, tname, tdesc), group in grouped:
                courses = group.sort_values('ê³¼ì •ìˆœì„œ')['ê³¼ì •ëª…'].tolist()
                curriculum_text += f"\n[íŠ¸ë™ {tid}: {tname}]\n- ì„¤ëª…: {tdesc}\n- ì—°ê³„ ê³¼ì • ìˆœì„œ: {' -> '.join(courses)}\n"
        except Exception as e:
            st.error(f"ì»¤ë¦¬í˜ëŸ¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ---------------------------------------------------------
    # 3. [í•™ìŠµ] ìˆ˜ì •.csv (RAG Knowledge Base)  
    # ---------------------------------------------------------
    # rag_file = os.path.join(DATA_DIR, "ìˆ˜ì •ì‹¤í—˜.csv")
    rag_file = os.path.join(DATA_DIR, "01_ë³‘í•©+ì •ê·œí™”_Data.csv")
    rag_data = []
    if os.path.exists(rag_file):
        try:
            try:
                df_rag = pd.read_csv(rag_file, encoding='cp949')
            except:
                df_rag = pd.read_csv(rag_file, encoding='utf-8')

            for _, row in df_rag.iterrows():
                rag_data.append({
                    'course': str(row.get('í›ˆë ¨ê³¼ì •ëª…(ì •ë‹µë¼ë²¨)', '')),
                    'pain': str(row.get('DT ì—ë¡œì‚¬í•­', '')),
                    'issue': str(row.get('ê¸°ì—…í˜„í™© ë° DTì´ìŠˆ', '')),
                    'as_is': str(row.get('AS-IS', '')),
                    'to_be': str(row.get('To_Be', '')),
                    'goal': str(row.get('ëª©í‘œ', '')),
                    'job': str(row.get('í›ˆë ¨ ì§ë¬´', ''))
                })
        except:
            pass

    return valid_courses, rag_data, curriculum_text


# ë°ì´í„° ë¡œë“œ ì‹¤í–‰
valid_courses, rag_data, curriculum_text = load_all_data(BASE_DIR)

# ==========================================
# 3. ë©”ì¸ UI
# ==========================================
st.title("ğŸ­ K-í•˜ì´í…Œí¬ ê¸°ì—… ì§„ë‹¨ ë° ê°•ì˜ ì¶”ì²œ (ì»¤ë¦¬í˜ëŸ¼ ê¸°ë°˜)")

if not valid_courses:
    st.stop()

with st.container():
    st.info("ğŸ’¡ 'ìˆ˜ì •.csv'ì˜ ë…¸ë€ìƒ‰ ì»¬ëŸ¼ì— í•´ë‹¹í•˜ëŠ” ê¸°ì—… ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with st.form("diagnosis_form"):
        col1, col2 = st.columns(2)
        with col1:
            industry = st.text_input("ì£¼ì—…ì¢…", placeholder="ì˜ˆ: ì œì¡°ì—… (ìë™ì°¨ ë¶€í’ˆ)")
            corp_type = st.selectbox("ê¸°ì—… ìœ í˜•", ["ë²•ì¸", "ê°œì¸ì‚¬ì—…ì", "ê¸°íƒ€"])
        with col2:
            comp_name = st.text_input("ì§€ì› ê¸°ì—…ëª…", placeholder="(ì£¼)OOO")
            date = st.date_input("ìˆ˜í–‰ ì¼ì")

        st.markdown("---")
        st.subheader("ğŸ“ ê¸°ì—… ì§„ë‹¨ ì…ë ¥")

        st.markdown("**1. ê¸°ì—…í˜„í™© ë° DT ì´ìŠˆ**")
        current_issue = st.text_area("ë‚´ìš© ì…ë ¥", height=100,
                                     placeholder="ì˜ˆ: ì£¼ìš” ìƒì‚°í’ˆì€ ì°¨ì²´ìš©ì ‘ì„¤ë¹„ì´ë©°, MES ë„ì… í•„ìš”ì„±ì€ ì¸ì§€í•˜ë‚˜ ì´í•´ ë¶€ì¡±ìœ¼ë¡œ êµ¬ì¶•í•˜ì§€ ëª»í•¨.")

        st.markdown("**2. DT ì• ë¡œì‚¬í•­ (Pain Points)**")
        pain_point = st.text_area("ë‚´ìš© ì…ë ¥", height=100, placeholder="ì˜ˆ: ì„¤ë¹„ ì œì‘ ì‹œ ë¬¼ë¥˜ ê´€ë¦¬ ì „ì‚°í™”ê°€ ì•ˆ ë˜ì–´ ì—…ë¬´ Loss ë°œìƒ.")

        st.markdown("**3. ê¸°íƒ€ ì˜ê²¬ (êµìœ¡ ë‹ˆì¦ˆ)**")
        etc_opinion = st.text_area("ë‚´ìš© ì…ë ¥", height=80, placeholder="ì˜ˆ: ìŠ¤ë§ˆíŠ¸ê³µì¥ êµ¬ì¶• ì‹¤ë¬´ ê²½í—˜ ë¶€ì¡±ìœ¼ë¡œ ê¸°ì´ˆ êµìœ¡ í¬ë§.")

        submit = st.form_submit_button("ğŸš€ AI ë§ì¶¤ ê°•ì˜ ì¶”ì²œ ì‹œì‘")

# ==========================================
# 4. AI ë¶„ì„ (Curriculum & RAG)
# ==========================================
if submit:
    # 1. RAG Context êµ¬ì„± (ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰)
    related_cases = []
    search_keywords = (pain_point + " " + current_issue).split()

    for case in rag_data:
        score = 0
        case_text = str(case['pain']) + str(case['issue'])
        for kw in search_keywords:
            if len(kw) > 1 and kw in case_text:
                score += 1
        if score > 0:
            related_cases.append((score, case))

    related_cases.sort(key=lambda x: x[0], reverse=True)
    top_cases = [c[1] for c in related_cases[:3]]

    rag_context_text = ""
    for i, case in enumerate(top_cases):
        rag_context_text += f"""
        [ìœ ì‚¬ ì‚¬ë¡€ {i + 1}]
        - ìƒí™©: {case['issue'][:50]}...
        - ì• ë¡œì‚¬í•­: {case['pain'][:50]}...
        - -> í•´ê²° ê°•ì˜: {case['course']}
        - -> ê²°ê³¼(To-Be): {case['to_be']}
        """

    available_courses_str = ", ".join(valid_courses)

    # 2. í”„ë¡¬í”„íŠ¸ ì‘ì„±
    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ê³µí•™ëŒ€í•™êµ K-í•˜ì´í…Œí¬ í”Œë«í¼ì˜ êµìœ¡ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ê¸°ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ **êµìœ¡ ì»¤ë¦¬í˜ëŸ¼(3ë‹¨ê³„ ì½”ìŠ¤)**ì„ ì„¤ê³„í•˜ì„¸ìš”.

    [ì…ë ¥ëœ ê¸°ì—… ì •ë³´]
    - ì£¼ì—…ì¢…: {industry}
    - ê¸°ì—…í˜„í™© ë° ì´ìŠˆ: {current_issue}
    - DT ì• ë¡œì‚¬í•­: {pain_point}
    - ê¸°íƒ€ ë‹ˆì¦ˆ: {etc_opinion}

    [ì œê³µëœ ì»¤ë¦¬í˜ëŸ¼ êµ¬ì¡° (Curriculum Tracks)]
    **ë°˜ë“œì‹œ ì•„ë˜ íŠ¸ë™ ì¤‘ì—ì„œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬, ê·¸ ì•ˆì— í¬í•¨ëœ ê°•ì˜ë“¤ë¡œ 3ë‹¨ê³„ ì½”ìŠ¤ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.**
    {curriculum_text}

    [ì°¸ê³  ê°€ëŠ¥í•œ ê³¼ê±° ì‚¬ë¡€ (RAG)]
    {rag_context_text}

    [ê²°ê³¼ë¬¼ ì‘ì„± ì–‘ì‹ (Strict Format)]
    ì œëª© í¬ê¸°ëŠ” ì‘ê²Œ(####) ì‘ì„±í•˜ì„¸ìš”.

    #### 1. ê¸°ì—… ì§„ë‹¨ ë‚´ìš©
    (ê¸°ì—…ì˜ í˜„í™©ê³¼ ì• ë¡œì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ êµìœ¡ í•„ìš”ì„±ì„ 3~4ì¤„ë¡œ ìš”ì•½)

    #### 2. ì¶”ì²œ í›ˆë ¨ê³¼ì • (3ë‹¨ê³„ ì»¤ë¦¬í˜ëŸ¼)
    ì„ ì •ëœ íŠ¸ë™: [íŠ¸ë™ëª… ì‘ì„±]

    - **Step 1 (ê¸°ì´ˆ/ì…ë¬¸):** [ê°•ì˜ëª…]
      - *ì„ ì • ì´ìœ :* (í•´ë‹¹ íŠ¸ë™ì˜ ê¸°ì´ˆ ê³¼ì •ìœ¼ë¡œì„œì˜ ì—­í•  ì„¤ëª…)

    - **Step 2 (í•µì‹¬/í•´ê²°):** [ê°•ì˜ëª…]
      - *ì„ ì • ì´ìœ :* (ê¸°ì—…ì˜ ì• ë¡œì‚¬í•­ "{pain_point}"ì„ ì§ì ‘ í•´ê²°í•˜ëŠ” í•µì‹¬ ê°•ì˜ì„)

    - **Step 3 (ì‹¬í™”/í™•ì¥):** [ê°•ì˜ëª…]
      - *ì„ ì • ì´ìœ :* (ì‹¬í™” í•™ìŠµ ë˜ëŠ” ì—°ê³„ ì—­ëŸ‰ ê°•í™” ëª©ì )

    #### 3. í›ˆë ¨ ëª©í‘œ
    (ì „ì²´ ì»¤ë¦¬í˜ëŸ¼ì„ í†µí•´ ë‹¬ì„±í•˜ê³ ì í•˜ëŠ” ëª©í‘œ)

    #### 4. í›ˆë ¨ ì£¼ìš” ë‚´ìš©
    (Step 2 í•µì‹¬ ê°•ì˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì£¼ìš” ë‚´ìš© 3ê°€ì§€ ìš”ì•½)

    #### 5. ê¸°ëŒ€ íš¨ê³¼ (AS-IS -> To-Be)
    - **AS-IS (í˜„ì¬):** {pain_point} ìš”ì•½
    - **To-Be (ë³€í™”):** êµìœ¡ ì´ìˆ˜ í›„ ê°œì„ ë  ëª¨ìŠµ
    """

    with st.spinner("ğŸ§  ìµœì ì˜ ì»¤ë¦¬í˜ëŸ¼ íŠ¸ë™ì„ ì„ ì •í•˜ê³  ë¡œë“œë§µì„ ì„¤ê³„ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            model = genai.GenerativeModel("gemini-2.5-flash")
            res = model.generate_content(prompt)

            st.markdown("### ğŸ“‹ K-í•˜ì´í…Œí¬ ë§ì¶¤í˜• êµìœ¡ ì»¤ë¦¬í˜ëŸ¼ ì œì•ˆì„œ")
            st.divider()
            st.markdown(res.text)

            with st.expander("ğŸ” AIê°€ ì°¸ê³ í•œ ìœ ì‚¬ ê¸°ì—… ì‚¬ë¡€ (RAG)"):
                st.write(rag_context_text)

            with st.expander("ğŸ“š ì „ì²´ ì»¤ë¦¬í˜ëŸ¼ ëª©ë¡ ë³´ê¸°"):
                st.text(curriculum_text)

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")